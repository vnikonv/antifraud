import streamlit as st
import pandas as pd
import numpy as np
import joblib
import json
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, precision_score, recall_score, roc_auc_score, accuracy_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from lightgbm import LGBMClassifier
from imblearn.under_sampling import RandomUnderSampler
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve
import time

st.set_page_config(page_title='Antifraud AI', page_icon=':mag:', layout='wide', initial_sidebar_state = 'auto')

st.markdown("""
<style>
/* –û–±—â–∏–π —Å—Ç–∏–ª—å —Å–∞–π–¥–±–∞—Ä–∞ */
section[data-testid="stSidebar"] {
    background-color: #00B2CA !important;
    color: white !important;
    padding-top: 10px !important;
}

/* –ù–∞–¥–ø–∏—Å–∏ –∏ —Ç–µ–∫—Å—Ç—ã –≤ —Å–∞–π–¥–±–∞—Ä–µ */
section[data-testid="stSidebar"] label,
section[data-testid="stSidebar"] div,
section[data-testid="stSidebar"] span {
    color: white !important;
    font-weight: 800 !important;
    font-size: 16px !important;
    border-radius: 12px !important;
}

/* –°–µ–ª–µ–∫—Ç–±–æ–∫—Å –∏ –ø–æ–ª—è –≤–≤–æ–¥–∞ */
section[data-testid="stSidebar"] div[role="combobox"],
section[data-testid="stSidebar"] input,
section[data-testid="stSidebar"] select {
    background-color: #000000 !important;
    border: none !important;
    border-radius: 8px !important;
    color: white !important;
    box-shadow: none !important;
}

/* SVG –∏–∫–æ–Ω–∫–∏ –≤ —Å–∞–π–¥–±–∞—Ä–µ */
section[data-testid="stSidebar"] svg {
    color: white !important;
}

/* –í—ã–ø–∞–¥–∞—é—â–∏–µ —Å–ø–∏—Å–∫–∏ –∏ –æ–ø—Ü–∏–∏ */
ul[role="listbox"],
li[role="option"] {
    background-color: #000000 !important;
    color: white !important;
    border-radius: 8px !important;
    border: none !important;
}

li[role="option"]:hover,
li[aria-selected="true"] {
    background-color: #000000 !important;
}

/* –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –≥—Ä–∞–Ω–∏—Ü –∏ —Ç–µ–Ω–µ–π –æ—Ç BaseWeb */
[data-baseweb="select"],
[data-baseweb="select"] * {
    background-color: #000000 !important;
    color: white !important;
    height: auto !important;
    border: none !important;
    box-shadow: none !important;
}

img {
    border-radius: 32px !important;
}



label div p {
    font-size: 24px !important;
    font-weight: 600 !important;
}

[data-testid="stMainBlockContainer"] {
    padding-top: 5% !important;
}

</style>
""", unsafe_allow_html=True)

st.set_page_config(page_title='Antifraud AI', page_icon = "ammit_search.png", layout = 'wide', initial_sidebar_state = 'auto')

icon = "nku_icon.png"

left_co, cent_co, last_co = st.columns([0.35, 0.3, 0.35])
with cent_co:
    st.image("ammit.png")
col1, col2 = st.columns([0.1, 0.9])
with col1:
    st.image(icon, width=100)
with col2:
    st.title("–ê–Ω—Ç–∏—Ñ—Ä–æ–¥ ML")

page = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É:", ["üèãÔ∏è‚Äç‚ôÇÔ∏è –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏", "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞"])

def align_features(df, feature_names):
    for col in feature_names:
        if col not in df.columns:
            df[col] = 0
    return df[feature_names]

# Classifier models selection
models = {
    "RandomForest": RandomForestClassifier(n_estimators=100, class_weight="balanced", random_state=42),
    "GradientBoosting": GradientBoostingClassifier(n_estimators=250, learning_rate=0.1, max_depth=6, random_state=42),
    "CatBoost": CatBoostClassifier(verbose=0, random_state=42),
    "LightGBM": LGBMClassifier(random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric="logloss", random_state=42)
}

if page == "üèãÔ∏è‚Äç‚ôÇÔ∏è –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏":
    st.header("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Å –∫–æ–ª–æ–Ω–∫–æ–π 'IsFraud'", type=["csv"])
    use_default = st.checkbox("–ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç")

    if use_default:
        uploaded_file = "./account_data.csv"
        st.info("‚úÖ –í—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞")
    

    model_name = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:", list(models.keys()))

    if uploaded_file:
        # Loading data
        df = pd.read_csv(uploaded_file)

        # –í—ã–±–æ—Ä –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é —Ñ–ª–∞–∂–∫–æ–≤
        selected_features = st.sidebar.multiselect(
            "üîß –û—Ç–º–µ—Ç—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è:",
            df.columns.tolist(),
            default=df.columns.tolist()
        )
        
        st.dataframe(df[selected_features])

        if st.button("üöÄ –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å"):
            # GB Flag = "IsFraud" column, binary classification task
            y = df["IsFraud"].map({"Yes": 1, "No": 0})
            X = df.drop(columns=["IsFraud"])

            # Detect categorical columns and encode them using LabelEncoder as str
            for col in X.select_dtypes(include="object").columns:
                le = LabelEncoder()
                X[col] = le.fit_transform(X[col].astype(str))

            # Balancing samples using RandomUnderSampler
            rus = RandomUnderSampler(random_state=42)
            X_res, y_res = rus.fit_resample(X, y)

            # Train/test split
            X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, stratify=y_res, random_state=42)

            # Feature scaling
            scaler = StandardScaler()
            X_train = scaler.fit_transform(X_train)
            X_test = scaler.transform(X_test)

            model = models[model_name]
            start_time = time.time()
            model.fit(X_train, y_train)
            train_time = time.time() - start_time

            y_pred = model.predict(X_test)
            y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None

            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred)
            recall = recall_score(y_test, y_pred)
            roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else 0.0
            gini = 2 * roc_auc - 1
            def ks_statistic(y_true, y_proba):
                from scipy.stats import ks_2samp
                return ks_2samp(y_proba[y_true == 1], y_proba[y_true == 0]).statistic
            ks = ks_statistic(y_test.to_numpy(), y_proba) if y_proba is not None else 0.0

            st.success(f"‚úÖ {model_name} –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")

            st.subheader("üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è (—Ç–µ—Å—Ç)")
            st.markdown(f"‚è± **–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:** {train_time:.2f} —Å–µ–∫")
            st.markdown(f"üìä **Gini –∏–Ω–¥–µ–∫—Å:** {gini:.4f}")
            st.markdown(f"üìä **KS –∏–Ω–¥–µ–∫—Å:** {ks:.4f}")
            st.markdown(f"‚úÖ **Accuracy:** {accuracy:.4f}")
            st.markdown(f"üéØ **Precision:** {precision:.4f}")
            st.markdown(f"üîÅ **Recall:** {recall:.4f}")

            y_train_pred = model.predict(X_train)
            y_train_proba = model.predict_proba(X_train)[:, 1] if hasattr(model, "predict_proba") else None
            accuracy_train = accuracy_score(y_train, y_train_pred)
            precision_train = precision_score(y_train, y_train_pred)
            recall_train = recall_score(y_train, y_train_pred)
            roc_auc_train = roc_auc_score(y_train, y_train_proba) if y_train_proba is not None else 0.0
            gini_train = 2 * roc_auc_train - 1
            ks_train = ks_statistic(y_train.to_numpy(), y_train_proba) if y_train_proba is not None else 0.0

            st.subheader("üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è (–æ–±—É—á–µ–Ω–∏–µ)")
            st.markdown(f"‚è± **–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:** {train_time:.2f} —Å–µ–∫")
            st.markdown(f"üìä **Gini –∏–Ω–¥–µ–∫—Å:** {gini_train:.4f}")
            st.markdown(f"üìä **KS –∏–Ω–¥–µ–∫—Å:** {ks_train:.4f}")
            st.markdown(f"‚úÖ **Accuracy:** {accuracy_train:.4f}")
            st.markdown(f"üéØ **Precision:** {precision_train:.4f}")
            st.markdown(f"üîÅ **Recall:** {recall_train:.4f}")

            st.subheader("üî¢ –ü—Ä–∏–º–µ—Ä —Ä–∞—Å—á—ë—Ç–æ–≤")
            metrics_df = pd.DataFrame({
                "–ú–µ—Ç—Ä–∏–∫–∞": ["–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (—Å–µ–∫)", "Gini", "KS", "Accuracy", "Precision", "Recall", "ROC AUC"],
                "–ó–Ω–∞—á–µ–Ω–∏–µ": [round(train_time, 2), round(gini, 4), round(ks, 4), round(accuracy, 4),
                             round(precision, 4), round(recall, 4), round(roc_auc, 4)]
            })
            metrics_df_train = pd.DataFrame({
                "–ú–µ—Ç—Ä–∏–∫–∞": ["–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (—Å–µ–∫)", "Gini", "KS", "Accuracy", "Precision", "Recall", "ROC AUC"],
                "–ó–Ω–∞—á–µ–Ω–∏–µ": [round(train_time, 2), round(gini_train, 4), round(ks_train, 4), round(accuracy_train, 4),
                             round(precision_train, 4), round(recall_train, 4), round(roc_auc_train, 4)]
            })
            st.subheader("üìä –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫ (—Ç–µ—Å—Ç)")
            st.table(metrics_df)

            st.subheader("üìä –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫ (–æ–±—É—á–µ–Ω–∏–µ)")
            st.table(metrics_df_train)

            fig_roc = plt.figure()
            fpr, tpr, _ = roc_curve(y_test, y_proba)
            plt.plot(fpr, tpr, label=f"ROC AUC = {roc_auc:.2f}")
            plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
            plt.xlabel("False Positive Rate")
            plt.ylabel("True Positive Rate")
            plt.title("ROC-–∫—Ä–∏–≤–∞—è")
            plt.legend()
            st.pyplot(fig_roc)

            st.subheader("üîç –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π")
            fig_hist = plt.figure()
            plt.hist(y_proba[y_test == 0], bins=30, alpha=0.6, label="–ö–ª–∞—Å—Å 0 (–Ω–µ –º–æ—à–µ–Ω–Ω–∏–∫)")
            plt.hist(y_proba[y_test == 1], bins=30, alpha=0.6, label="–ö–ª–∞—Å—Å 1 (–º–æ—à–µ–Ω–Ω–∏–∫)")
            plt.title("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –ø–æ –∫–ª–∞—Å—Å–∞–º")
            plt.xlabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å")
            plt.ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
            plt.legend()
            st.pyplot(fig_hist)
            st.markdown(f"**–†–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–π –±–∞–ª–ª (–ø—Ä–∏–º–µ—Ä):** {y_pred[0]}")
            st.markdown(f"**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ (–ø—Ä–∏–º–µ—Ä):** {y_proba[0]:.4f}")

            st.subheader("üìå –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ")
            st.code(", ".join(X.columns))

            subset_info = pd.DataFrame({
                "target": pd.concat([y_train, y_test], ignore_index=True),
                "subset": ["train"] * len(y_train) + ["test"] * len(y_test)
            })
            st.subheader("üß™ –†–∞–∑–º–µ—Ç–∫–∞ –≤—ã–±–æ—Ä–æ–∫")
            st.dataframe(subset_info.sample(10, random_state=42))

            X_test_raw = pd.DataFrame(scaler.inverse_transform(X_test), columns=X.columns)
            results_df = X_test_raw.copy()
            results_df["–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å"] = y_pred
            results_df["–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å"] = y_proba
            results_df["–ò—Å—Ç–∏–Ω–Ω—ã–π IsFraud"] = y_test.values

            csv = results_df.to_csv(index=False).encode("utf-8")
            col_csv, col_xls = st.columns(2)
            with col_csv:
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –≤ CSV",
                    data=csv,
                    file_name="test_predictions.csv",
                    mime="text/csv"
                )
            with col_xls:
                import io
                from openpyxl import Workbook
                wb = Workbook()
                ws = wb.active
                ws.title = "Test Predictions"
                for col_num, column in enumerate(results_df.columns, 1):
                    ws.cell(row=1, column=col_num, value=column)
                for row_num, row in enumerate(results_df.values, 2):
                    for col_num, value in enumerate(row, 1):
                        ws.cell(row=row_num, column=col_num, value=value)
                excel_buffer = io.BytesIO()
                wb.save(excel_buffer)
                excel_buffer.seek(0)
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –≤ XLS",
                    data=excel_buffer.getvalue(),
                    file_name="test_predictions.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

            st.success(f"‚úÖ {model_name} –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")

            os.makedirs("models", exist_ok=True)
            
            # Save model
            joblib.dump(model, f"models/{model_name}_model.pkl")

                # Save scaler
            joblib.dump(scaler, f"models/{model_name}_scaler.pkl")

            # Save feature names
            with open(f"models/{model_name}_features.json", "w") as f:
                json.dump(X.columns.tolist(), f)

if page == "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞":
    # Scan all models that have a saved _model.pkl file
    available_models = [
    f.replace("_model.pkl", "")
    for f in os.listdir("models")
    if f.endswith("_model.pkl")
    ]

    if available_models:
        selected_model = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:", available_models)

        model = joblib.load(f"models/{selected_model}_model.pkl")
        scaler = joblib.load(f"models/{selected_model}_scaler.pkl")

        with open(f"models/{selected_model}_features.json", "r") as f:

            feature_names = json.load(f)

        uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª", type=["csv", "xlsx", "xls"])

        if uploaded_file:
            df = pd.read_csv(uploaded_file) if uploaded_file.name.endswith(".csv") else pd.read_excel(uploaded_file)
            df_original = df.copy()

            # Align features (implement align_features if needed)
            df_aligned = align_features(df, feature_names)
            # Encode categorical columns
            for col in df_aligned.select_dtypes(include="object").columns:
                le = LabelEncoder()
                df_aligned[col] = le.fit_transform(df_aligned[col].astype(str))
            imputer = SimpleImputer(strategy="mean")
            df_imputed = pd.DataFrame(imputer.fit_transform(df_aligned), columns=df_aligned.columns)
            df_scaled = pd.DataFrame(scaler.transform(df_imputed), columns=df_imputed.columns)

            predictions = model.predict_proba(df_scaled)[:, 1]
            is_fraud_pred = model.predict(df_scaled)
            # Create output DataFrame with only index, –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞, and IsFraud
            output_df = pd.DataFrame({
                "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞": predictions,
                "IsFraud": is_fraud_pred
            })
            st.subheader("üìã –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
            rows_to_display = st.slider(
                "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã—Ö —Å—Ç—Ä–æ–∫",
                min_value=0,
                max_value=min(100, len(output_df)),
                value=min(10, len(output_df)),
                step=1
            )
            st.dataframe(output_df.head(rows_to_display))
            
            # Two download buttons: CSV and XLS
            col_csv, col_xls = st.columns(2)
            with col_csv:
                csv_pred = output_df.to_csv(index=False).encode("utf-8")
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ CSV",
                    data=csv_pred,
                    file_name="predictions.csv",
                    mime="text/csv"
                )
            with col_xls:
                import io
                from openpyxl import Workbook
                wb = Workbook()
                ws = wb.active
                ws.title = "Predictions"
                for col_num, column in enumerate(output_df.columns, 1):
                    ws.cell(row=1, column=col_num, value=column)
                for row_num, row in enumerate(output_df.values, 2):
                    for col_num, value in enumerate(row, 1):
                        ws.cell(row=row_num, column=col_num, value=value)
                excel_buffer = io.BytesIO()
                wb.save(excel_buffer)
                excel_buffer.seek(0)
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ XLS",
                    data=excel_buffer.getvalue(),
                    file_name="predictions.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
           
    else:
        st.error("‚ùå –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å")